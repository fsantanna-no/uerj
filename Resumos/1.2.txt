# 1.2 Compilação e Interpretação de Linguagens de Programação

Computadores somente são capazes de executar instruções muito simples e que não 
refletem a maneira como os seres humanos se comunicam, por isso, praticamente 
todo software é escrito em uma linguagem de programação.

De maneira geral, LPs oferecem construções linguísticas mais próximas às 
linguagens naturais que, após serem combinadas em um programa por um humano, 
são automaticamente traduzidas para instruções entendidas pela máquina, num 
processo conhecido como tradução:

    [TRADUÇÃO ENTRE LP E MÁQUINA]
    abcxyz  -> |tradutor| -> 010101 -> |execução|
    (humano)                 (máquina)
    (código fonte)           (código binário)

Existem duas abordagens para a tradução de linguagens de programação para 
linguagens de máquina.
Na compilação, o código fonte é traduzido por completo para a representação 
binária antes da máquina executá-lo.
Na interpretação, o código fonte é traduzido incrementalmente, durante a 
execução do programa.
Em geral, a escolha por compilação resulta em maior velocidade (assumindo que a 
compilação pode ser feita com antecedência à execução), enquanto que a 
interpretação traz maior flexibilidade.

## Separação entre Interpretação e Compilação

Na prática, não existe um consenso sobre uma linha bem definida que separe 
compliação e interpretação, sendo preciso entender melhor os "trade-offs" entre 
as duas abordagens:

INTERPRETAÇÃO PURA                     COMPILAÇÃO PURA
Shell,REPL          VM-din ||| VM-sta  C/C++
sh    DrScheme      Lua,JS     Java/C#

Na interpretação pura, por exemplo em "shells" de linha de comando e ambientes 
de programação REPL ("read-eval-print-loop"), cada linha digitada é traduzida e 
executada antes da seguinte, mas mantendo o estado global entre as execuções.

O surgimento de máquinas virtuais introduzu um intermediário entre a tradução e 
execução de programas:

    código  -> (tradução) -> bytecodes -> (VM) -> execução
    fonte

Com essa abordagem, a máquina real agora interpreta "bytecodes" de uma máquina 
virtual, mas o código fonte continua precisando ser traduzido (compilado) para 
bytecodes em uma etapa anterior.

Considerando a fronteira entre os bytecodes e a máquina real, linguagens como 
Java e C# devem ser consideradas interpretadas.
Alguns autores, no entanto, ponderam que para uma linguagem ser considerada 
interpretada, é necessário que ela oferece uma primitiva "eval" que permite 
traduzir novos trechos de código durante a execução do programa:

    código  -> (tradução) -> bytecodes -> (VM) -> execução
    fonte
                    \-------------------------------/

Em outras palavras, é necessário que o tradutor esteja embutido no próprio 
programa.
Essa definição exlcui as linguagens tipadas estaticamente, mas inclui as 
linguagens dinâmicas, mesmo as que são traduzidas para bytecode antes da 
execução.

## Estrutura Geral de Compiladores e Interpretadores

O processo de tradução de programas é dividio em diversas fases, como ilustra o 
diagrama a seguir:

    ESTRUTURA GERAL DE UM TRADUTOR
    - Análise / Front-end:
        - CARACTERES       --[analisador léxico]-->
          TOKENS           --[analisador sintático]-->
          ÁRVORE SINTÁTICA --[analisador semântico]-->
          ÁRVORE SINTÁTICA --[gerador de código intermediário]--> RI/CI
    - Síntese / Back-end:
        - RI/CI             --[montador]-->
          CÓDIGO DE MÁQUINA --[otimizador]-->
          CÓDIGO DE MÁQUINA --[ligador]-->
          CÓDIGO DE MÁQUINA (não relocável)
    - Tabela de Símbolos
        - preenchida e compartilhada por todas as fases
        - banco de dados com linha,tipo,escopo

O "front end" (análise) lida com a sintaxe e semântica estática da linguagem, 
verificando se o programa de entrada é válido e gerando uma representação 
intermediária (e.g., assembly), com os detalhes sintáticos eliminados.
Já o "back end" (síntese) lida com a geração de código para uma arquitetura 
específica, transformando a representação intermediária no código final.
Idealmente, essa divisão bem definida permite a combinação de diferentes "back 
ends" com diferente "front ends", permitindo compilar diferentes linguagens 
para diferentes máquinas (L x M combinações).
Essa arquitetura é seguida por ferramentas bem sucedidas, tais como o GCC e o 
LLVM, que permitem que diferentes linguagens sejam compiladas para uma 
representação intermediária que pode em seguida ser compilada para diferentes 
plataformas.

Em linguagens compiladas, grande parte do esforço se concentra na "back-end", 
onde ocorrem todas otimizações e a geração para a arquitetura final.
Já em linguagens interpretadas, se a representação intermediária já forem
bytecodes para uma máquina virtual, o "front end" pode ser eliminado por 
completo.
Note que o "back end" deve estar disponível durante toda a execução de 
programas interpretados.

## Sintaxe

As duas primeiras fases do "front end", análise léxica e sintática, lidam com a 
forma da LP.
O objetivo dessas fases é o de reconhecer e transformar a entrada textual 
"concreta" em uma forma abstrata, padronizada, de mais fácil manipulação para 
as fases seguintes.
Tipicamente o programa de entrada é transformado em uma árvore sintática 
abstrata (AST).
Como exemplo, independentemente da sintaxe concreta para somar dois números 
("2+1" em C ou "(+ 2 1)" em LISP), a representação abstrata será a mesma:
        +
       / \
      2   1

Note que em geral uma LP pode descrever infinitos programas, dado que suas 
construções permitem repetições ou composições:

    [IDENTIFICADORES E COMANDOS POSSÍVEIS]
    x, xx, xxx, ...                 (infinitos identificadores)
    while(1) { while(1) { ... } }   (infinitos comandos while)

Dessa maneira, as regras que descrevem o léxico e a sintaxe devem ser 
expressadas em "meta-linguages" capazes de exprimir todas as infinitas 
possibilidades através de uma forma finita.
As duas meta-linguagens mais comuns são as expressões regulares, para o léxico, 
e as BNFs (Backus-Naur form), para a sintaxe.

### Análise léxica (scanning)

A primeira fase do compilador lida com a transformação de um fluxo de 
caracteres escritos na LP para um fluxo de tokens a ser repassado para a 
análise sintática.
Tipicamente os tokens representam números, identificadores, palavras reservadas 
e operadores aceitos pela LP.
Além do que ele representa, um token pode carregar atributos adicionais, tais 
como o seu conteúdo completo (lexeme) e a linha onde aparece.

O exemplo a seguir, em C, separa uma sequência de caracteres em tokens:

    x = 1;  =>  <ID,"x",1>  <"=",1>  <NUM,"1",1> <";",1>

O programa que reconhece a entrada como válida e a transforma em tokens é 
conhecido como "scanner" e pode ser gerado automaticamente por uma ferramenta 
"geradora de scanners".
Essas ferramentas se baseiam na teoria de linguagens regulares (LRs) e sua 
correspondência com autômatos finitos determinísticos (DFAs), ou seja, que 
qualquer linguagem regular pode ser reconhecida por um DFA.

### Análise sintática (parsing)

As contruções sintáticas são consideravelmente mais complexas que as léxicas, 
tipicamente descrevendo aninhamento e regras recursivas.
Dessa forma, um formalismo mais poderoso que LRs se faz necessário, como por 
exemplo as linguagens livre de contexto (CFL) e sua correspondência com 
autômatos de pilha.

A toda LP está associada uma gramática que descreve as construções aceitas pela 
linguagem.
A notação BNF é usada para esse fim e é composta pelos seguintes elementos:

    - terminais:       representam os tokens vindo do scanner
    - não terminais:   representam as regras de composição
    - produções:       descrevem as regras de composição
    - símbolo inicial: um não terminal representando programas válidos (em
                       geral o que aparece em primeiro na gramática)

A BNF a seguir ilustra uma gramática com aninhamento e recursão:

    Exp := Exp '+' Exp      (regra com recursão)
        | '(' Exp ')'       (regra com aninhamento)
        |  <id>             (regra básica)

A partir do símbolo inicial, essa gramática pode gerar expressões como "v", 
"((v))" e "v+(v)".

BNFs descrevem gramáticas livres de contexto (CFGs), sendo que o lado esquerdo 
de cada produção só pode conter um único símbolo não terminal (e nenhum 
terminal).

O programa que reconhece programas de entrada de acordo com uma CFG é conhecido 
como "parser" e também pode ser gerado automaticamente por uma ferramenta 
"geradora de parsers".

Existem duas técnicas básicas para a construção de parsers, ambas usam um 
algoritmo determinístico com o auxílio de um pilha.
Na técnica top down, também conhecida como preditiva, o topo da pilha sempre 
contém o não terminal da CFG que será reconhecido a seguir, começando pelo 
símbolo inicial da CFG.
Na técnica bottom up, o topo da pilha sempre contém o último símbolo 
reconhecido, sempre terminando com o símbolo inicial da CFG (em caso de 
sucesso).

## Representações Intermediárias

Como principais requisitos, a linguagem ou representação intermediária (RIs) 
deve ser
(1) independente de arquitetura, i.e., com operações simples que não visam uma 
arquitetura específica (e.g., instruções CISC que efetuam diversas operações);
(2) facilmente geradas e traduzidas entre front ends e back ends, por exemplo 
com uma forma regular (e.g., árvore ou código de 3 endereços);
(3) otimizáveis, com o mínimo de dependência entre instruções (e.g., uso de 
offsets ou referências), de maneira a permitir manipulações arbritárias no 
código.

RIs devem encontrar um balanço de expressividade entre as possíveis linguagens
sendo compiladas e as possíveis arquiteturas alvo.
Em geral, RIs eliminam estrutras complexas de controle (e.g., switch-case, 
for), mas também não se limitam a recursos finitos de arquiteturas finais 
(e.g., número fixo de registradores).

## Ambientes de Tempo de Execução

O ambiente de execução de uma linguagem controla o estado global da memória, 
I/O, registradores e CPU.
É ele que vai colocar a máquina em um estado consistente para iniciar a 
execução do programa, determinar as chamadas de entrada e saída disponíveis, 
administrar funcionalidades como alocação e coleta de memória e escalonar 
linhas de execução no caso de linguagens concorrentes.
Durante a execução normal, a CPU basicamente entra em um ciclo de buscar a 
próxima instrução, decodificá-la e executá-la.

Mesmo linguagens compiladas básicas como C possuem um ambiente de execução 
("crt0.o", c-run-time) que é embutido no programa de maneira a inicializar a 
pilha, preencher o vetor de interrupção, zerar a memória BSS antes de chamar a 
"main" do programa.

No caso da interpretação, além do ambiente de execução também embutir o front 
end de tradução, o ciclo de busca/decodificação/execução é simulado pela 
máquina virtual, sendo o principal custo de execução associado à 
virtualização.

A virtualização traz o benefício de portabilidade, uma vez que um bytecode 
compilado para uma certa máquina virtual pode executar em diferentes 
implementações para arquiteturas finais.

Uma outra vantagem da interpretação de bytecodes é a possível 
interoperabilidade entre linguagens com paradigmas antagônicos.
Como exemplo, o mesmo bytecode gerado por Java para executar na JVM, também é 
gerado por Clojure, uma linguagem funcional com tipagem dinâmica.
Essa tendência também pode ser observada no mundo da Web, com novas linguagens 
que enchergam os browsers como máquina virtuais que executam "bytecodes em 
JavaScript" (ClojureScript, CoffeeScript, Elm, entre outras).

Uma variação para a interpretação é o uso de JITs ("just-in-time-compilation"), 
que compilam o código durante a execução do programa.
Para códigos que executam com muita frequência (e.g., loops), a latência
inicial de compilação pode ser compensada no longo prazo, se o trecho é 
executado muitas vezes.
Em teoria, JIT podem até ser mais rápidos que a pré-compilação, pois podem 
tirar proveito do máquina em que estão executando no momento e usarem intruções 
específicas.
